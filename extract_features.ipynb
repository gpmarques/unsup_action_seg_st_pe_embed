{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767b5160-6c59-49f4-856d-b34fd7de2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/miniconda3/envs/as_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.decomposition.pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/guilherme/miniconda3/envs/as_env/lib/python3.7/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.7.0` and `torch==1.6.0` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n",
      "/home/guilherme/action_eval/finch.py:13: UserWarning: pyflann not installed: No module named 'pyflann'\n",
      "  warnings.warn('pyflann not installed: {}'.format(e))\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from video import Video\n",
    "import random\n",
    "from extractors import ExtractorFactory\n",
    "from clusters import ClusterFactory\n",
    "from mxnet import nd, gpu\n",
    "from s3 import S3\n",
    "import io\n",
    "import cv2\n",
    "import finch\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import math\n",
    "from pprint import pprint\n",
    "from accuracy import Accuracy\n",
    "from finch import FINCH\n",
    "from npy import Npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3034948-25c6-4794-b651-71576638e323",
   "metadata": {},
   "source": [
    "# Getting Breakfast's video paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3903f-fd8f-4b31-a01a-0ee78851d7ce",
   "metadata": {},
   "source": [
    "### getting ground truth paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62028194-a1b9-4115-bd68-45adf172cfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['segmentation_coarse', 'scrambledegg']\n",
      "['segmentation_coarse', 'milk']\n",
      "['segmentation_coarse', 'coffee']\n",
      "['segmentation_coarse', 'salat']\n",
      "['segmentation_coarse', 'cereals']\n",
      "['segmentation_coarse', 'juice']\n",
      "['segmentation_coarse', 'sandwich']\n",
      "['segmentation_coarse', 'friedegg']\n",
      "['segmentation_coarse', 'pancake']\n",
      "['segmentation_coarse', 'tea']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_paths = {}\n",
    "for path, subdirs, files in os.walk('segmentation_coarse'):\n",
    "    split_path = path.split(\"/\")\n",
    "    if len(split_path) == 2:\n",
    "        print(split_path)\n",
    "        gt_paths[split_path[-1]] = []\n",
    "        for name in files:\n",
    "            if name.split(\".\")[-1] == 'txt':\n",
    "                gt_paths[split_path[-1]].append(os.path.join(path, name))\n",
    "\n",
    "sum([len(paths) for _, paths in gt_paths.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c818772-8d1c-45f2-be87-9434ebbbb9e9",
   "metadata": {},
   "source": [
    "### Function that transforms a ground truth file path to a video file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c87da7-4c76-4de8-a560-b5782dc62581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def gt_to_vd_path(gt_path):\n",
    "    vd_root_folder = '../BreakfastII_15fps_qvga_sync'\n",
    "    splitted_path = gt_path.split(\"/\")[-1].split(\"_\")\n",
    "    pfolder = splitted_path[0]\n",
    "    splitted_path[-1] = splitted_path[-1].split(\".\")[0]\n",
    "\n",
    "    if 'stereo' in gt_path:\n",
    "        recfolder = splitted_path[1][:-2]\n",
    "        filename = \"_\".join([splitted_path[0], splitted_path[-1], 'ch1'])\n",
    "        vd_path = \"/\".join([vd_root_folder, pfolder, recfolder, filename + '.avi'])\n",
    "        if Path(vd_path).exists():\n",
    "            return vd_path\n",
    "        else:\n",
    "            filename = \"_\".join([splitted_path[0], splitted_path[-1], 'ch0'])\n",
    "            vd_path = \"/\".join([vd_root_folder, pfolder, recfolder, filename + '.avi'])\n",
    "            return vd_path\n",
    "    else:\n",
    "        recfolder = splitted_path[1]\n",
    "        filename = \"_\".join([splitted_path[0], splitted_path[-1]])\n",
    "    \n",
    "    return \"/\".join([vd_root_folder, pfolder, recfolder, filename + '.avi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06dfb3a-a31e-4a13-8174-11865a442b4e",
   "metadata": {},
   "source": [
    "## Getting INRIA's video paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbcf081-9a61-42f2-b768-56bd4d4aadf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_video_paths(root_folder, video_ext):\n",
    "    paths = []\n",
    "    for path, subdirs, files in os.walk(root_folder):\n",
    "        for name in files:\n",
    "            if name.split(\".\")[-1] == video_ext:\n",
    "                paths.append(os.path.join(path, name))\n",
    "    return paths\n",
    "\n",
    "paths = get_video_paths(root_folder='data_new', video_ext='avi')\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53639583-1ad8-45ef-8223-0116aa77e939",
   "metadata": {},
   "source": [
    "## Extracting SlowFast Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db292d5-5774-4ae1-8a36-0ef29cd767fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_len = 32\n",
    "extractor = ExtractorFactory.get(ExtractorFactory.SLOWFAST.value)(clip_len=clip_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd4d85-f712-4a63-9c48-e0a92b040c92",
   "metadata": {},
   "source": [
    "### for Breakfast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47985bd2-ee8e-4c66-b298-7ec46fbfd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, gts in gt_paths.items():\n",
    "    print(key)\n",
    "    for gt_path in gts:\n",
    "        vd_path = gt_to_vd_path(gt_path)\n",
    "        video = Video(vd_path, \"_\".join([ExtractorFactory.SLOWFAST.value, str(clip_len)]))\n",
    "        print(gt_path)\n",
    "        extractor.extract(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9affda5-f506-4d63-8992-d0c281f7c142",
   "metadata": {},
   "source": [
    "### for INRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f5b73-f4f1-4fe1-b6aa-0a487ee6d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    video = Video(path, \"_\".join([ExtractorFactory.SLOWFAST.value, str(clip_len)]))\n",
    "    if video.features.has_features:\n",
    "        continue\n",
    "    print(path)\n",
    "    extractor.extract(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af170281-8173-4721-869b-0842dbdc679a",
   "metadata": {},
   "source": [
    "## Extracting I3D features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03575303-d43b-46fb-885c-3db8ee0b51b6",
   "metadata": {},
   "source": [
    "### for INRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b327c5-5881-40ee-8160-331c157accbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create this file\n",
    "with open('./video_paths.txt', 'w') as paths_file:\n",
    "    for path in paths:\n",
    "        paths_file.write(\"../action_eval/\"+path+\"\\n\")\n",
    "\n",
    "# run this command in terminal to extract the features inside the video_features folder\n",
    "# please, remember to substitute\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 10 --step_size 10 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 16 --step_size 16 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 24 --step_size 24 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 32 --step_size 32 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 40 --step_size 40 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 48 --step_size 48 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt\n",
    "# !python main.py --feature_type i3d --device_ids 0 --stack_size 64 --step_size 64 --output_path ../action_eval/inria_features --on_extraction save_numpy --file_with_video_paths ../action_eval/video_paths.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b55f61-2a93-4013-87b6-5282155eba4f",
   "metadata": {},
   "source": [
    "### for Breakfast dataset\n",
    "\n",
    "Copy the `extract_features.py` file to the video_features folder and run the command below.\n",
    "```\n",
    "python extract_features.py\n",
    "```\n",
    "Don't forget to run this script for each segment size mentioned in the paper, just substitute the proper var inside the script to do this,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "as_env",
   "language": "python",
   "name": "as_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
